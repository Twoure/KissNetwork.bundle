#!/usr/bin/env python

"""
KissNetwork shared code.
Manipulate Headers for Kiss domains.
"""

from __builtin__ import hasattr
import os
from io import open
import json
from threading import Thread, Event
import domain as Domain
import common as Common
from preferences import Prefs

# Import Shared Library Modules
import requests
try:
    import cfscrape
except ImportError, e:
    cfscrape = None
    Log.Critical('* cfscrape import ERROR: {}'.format(e))

####################################################################################################
def CFTest(kind):
    """test cfscrape"""
    cookie, ua = cfscrape.get_cookie_string(url=Common.GetBaseURL(Common.DomainDict(kind)), user_agent=Common.USER_AGENT)
    return str(cookie)

####################################################################################################
class KissHeaders(object):
    def __init__(self):
        self.user_agent = Common.USER_AGENT
        self.header_file = os.path.join(Common.SUPPORT_PATH, 'Header_Dict')
        self.header_data = dict()
        self.event = Event()

    def save_dict(self):
        if not self.header_data:
            Log.Error('* No header content to Save')
            return False

        with open(self.header_file, 'wb') as f:
            json.dump(self.header_data, f, indent=4, sort_keys=True, separators=(',', ': '))

        if os.path.isfile(self.header_file) and os.stat(self.header_file).st_size != 0:
            Log.Debug('* Header file Saved')
            return True
        Log.Error('* Header file NOT Saved')
        return False

    def load_dict(self):
        # clear old dict first
        self.header_data.clear()

        # check and load new dict
        if os.path.isfile(self.header_file) and os.stat(self.header_file).st_size != 0:
            with open(self.header_file, 'rb') as f:
                data = json.load(f)
            if data:
                self.header_data.update(data)
            return bool(self.header_data)

        # file does not exist or is empty, create new file and fill
        if not self.create_dict():
            Log.Error('* cannot create new header dict')
            return False
        if not self.load_dict():
            Log.Error('* tried to re-save header dict but failed.')
            return False
        return bool(self.header_data)

    def set_header(self, url):
        base_url = Common.GetBaseURL(url)
        type_title = Common.GetTypeTitle(url)
        try:
            try:
                cookie, user_agent = cfscrape.get_cookie_string(url=base_url, user_agent=self.user_agent)
                r_cf_clearance = Regex(r'cf_clearance\=.*\-(\d+)\-(\d+)').search(cookie)
            except:
                Log.Exception(u'* set_header cfscrape.get_cookie_string Error: >>>')
                cookie = 'na'
                user_agent = self.user_agent
                r_cf_clearance = None

            if r_cf_clearance:
                date = int(r_cf_clearance.group(1))
                expire = date + int(r_cf_clearance.group(2))
            else:
                expire = Datetime.TimestampFromDatetime(Datetime.Now() + Datetime.Delta(days=364))
                Log.Warn(u'* set_header Error: Cannot calculate expire time for {}.'.format(base_url))

            return {
                type_title: {
                    'cookie': cookie, 'user-agent': user_agent, 'referer': base_url,
                    'expire': '{}'.format(expire)
                    }
                }
        except:
            Log.Exception(u'* set_header() Error: >>>')
            return {}

    def create_dict(self):
        Log.Debug('* Creating New Header Dict')
        for (type_title, base_url) in Common.BaseURLListTuple():
            self.header_data.update(self.set_header(base_url))
        if not self.save_dict():
            Log.Error('* failed to save new header dict')
            return False
        return True

    def get_headers_for_url(self, url, update=False):
        type_title = Common.GetTypeTitle(url)
        if not self.header_data:
            Log("* Loading Header Dict")
            self.load_dict()
            if not self.header_data:
                Log.Error(u'* Cannot load {} header, because header file does not exist'.format(type_title))
                return {}

        base_url = Common.GetBaseURL(url)
        current_timestamp = int(Datetime.TimestampFromDatetime(Datetime.Now()))

        if len(self.header_data) >= 1:
            update2 = True
            if type_title in self.header_data.keys():
                if 'expire' in self.header_data[type_title].keys():
                    expire = int(self.header_data[type_title]['expire'])
                    update2 = True if update else (True if current_timestamp >= expire else False)

            if update2:
                Log.Debug(u'* {} cookies expired. Collecting fresh cookies.'.format(type_title))

                self.header_data.update(self.set_header(base_url))

                Log.Debug('* Updated {} Header to >>'.format(type_title))
                Log.Debug('* {}'.format(self.header_data[type_title]))

                self.save_dict()
                Log.Debug('* New Cookies saved for {} Header'.format(base_url))
            else:
                if 'expire' in self.header_data[type_title].keys():
                    current_datetime = Datetime.FromTimestamp(current_timestamp)
                    expire_datetime = Datetime.FromTimestamp(int(expire))
                    deltatime = str(expire_datetime - current_datetime)
                    Log.Debug(u'* {} cookies expire in {}'.format(type_title, deltatime))
                else:
                    Log.Warn('* No Expire time within {} cookies'.format(type_title))
        else:
            self.create_dict()

        # setup headers to return, do not want date in header field
        return {
            'cookie': self.header_data[type_title]['cookie'],
            'user-agent': self.header_data[type_title]['user-agent'],
            'referer': self.header_data[type_title]['referer']
            }

    def check_all_headers(self):
        if not self.header_data:
            self.load_dict()
            if not self.header_data:
                Log.Error('* Cannot check all headers, because header file does not exist')
                return False

        updated = False
        for (type_title, base_url) in Common.BaseURLListTuple():
            site_pref = 'kissasian' if type_title == 'Drama' else 'kiss{}'.format(type_title.lower())
            if len(self.header_data) > 1 and Prefs[site_pref]:
                expire = int(self.header_data[type_title]['expire'])
                current_timestamp = int(Datetime.TimestampFromDatetime(Datetime.Now()))
                if current_timestamp >= expire:
                    updated = True
                    Log.Debug(u'* {} cookies expired. Collecting fresh cookies.'.format(type_title))
                    self.header_data.update(self.set_header(base_url))
                else:
                    if 'expire' in self.header_data[type_title].keys():
                        current_datetime = Datetime.FromTimestamp(current_timestamp)
                        expire_datetime = Datetime.FromTimestamp(int(expire))
                        deltatime = str(expire_datetime - current_datetime)
                        Log.Debug(u'* {} cookies expire in {}'.format(type_title, deltatime))
                    else:
                        Log.Warn(u'* No Expire time within {} cookies'.format(type_title))

        if updated:
            if not self.save_dict():
                Log.Error('* Failed to save new header data to file')
        self.event.set()
        Log('* Finished checking all headers')
        return updated

    def init_headers(self, init=False):
        if init:
            self.event.clear()
            Log('* Starting check_all_headers() Thread')
            self.que_thread = Thread(target=self.check_all_headers)
            self.que_thread.start()
        elif hasattr(self, 'que_thread') and self.event.is_set():
            Log('* {}'.format(self.que_thread))
            Log('* Thread Status = {}'.format(self.que_thread.is_alive()))
            Log('* Finished initializing Headers')
            return True
        elif hasattr(self, 'que_thread'):
            Log('* {}'.format(self.que_thread))
            Log('* Thread Status = {}'.format(self.que_thread.is_alive()))
            Log('* Headers are initializing')
        else:
            Log('* Headers initialization Skipping.')
            return True
        return False

Headers = KissHeaders()
